{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "pytorch_tensor_intro.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEleuBBpyytD"
      },
      "source": [
        "2021 Takahiro Shinozaki @ Tokyo Tech\n",
        "\n",
        "Quick introduction of pytorch tensor and gradient calculation\n",
        "\n",
        "References: \n",
        "*   https://pytorch.org/tutorials/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYQtTNDy5Btd"
      },
      "source": [
        "# if you run this notebook on TSUBAME, you have to run the following code without comment out\n",
        "# !pip install torch\n",
        "# !pip install matplotlib\n",
        "\n"
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "# library to visualize the strucure of computation\n",
        "! pip install torchviz\n",
        "from torchviz import make_dot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeGxU788xWlI"
      },
      "source": [
        "# Check if GPU is available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td_teMPo52EE"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    print('CUDA（GPU）is available')\n",
        "else:\n",
        "    print('CUDA（GPU）is not available')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy1gZe3Oxcec"
      },
      "source": [
        "# Operate PyTorch tenosrs\n",
        "\n",
        "## Data type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOj7Lzo8xgVw"
      },
      "source": [
        "x = torch.tensor(1)\n",
        "print(x.dtype)\n",
        "\n",
        "x = torch.tensor(1.0)\n",
        "print(x.dtype)\n",
        "\n",
        "x = torch.tensor(1.0, dtype=torch.float64)\n",
        "print(x.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J7KDsz5xjCP"
      },
      "source": [
        "## Scalar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WuRawD56TOT"
      },
      "source": [
        "x = torch.tensor(7)\n",
        "print('x =', x)\n",
        "\n",
        "y = x**2+1\n",
        "print('y =', y)\n",
        "\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.exp(x)\n",
        "print('y =', y)\n",
        "\n",
        "y = torch.cos(x)\n",
        "print('y =', y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIB1rGC4xqZa"
      },
      "source": [
        "## Vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snuMqMBFnn0B"
      },
      "source": [
        "x = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)\n",
        "print('x =', x)\n",
        "print('x**0.5 =', x ** 0.5)\n",
        "\n",
        "x = torch.linspace(0, 10, 41)\n",
        "print('x =', x)\n",
        "print('x[2]', x[2])\n",
        "y = torch.cos(x)\n",
        "# Draw a figure\n",
        "plt.figure()\n",
        "plt.plot(x, y)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('cos(x)')\n",
        "plt.xlim(0, x[-1])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaTr_33Ixw4b"
      },
      "source": [
        "## Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdPif6XaowD3"
      },
      "source": [
        "x = torch.tensor([[1,2], [3,4]])\n",
        "print(x)\n",
        "print(x.dtype)\n",
        "\n",
        "y = x * 2\n",
        "print(y)\n",
        "\n",
        "y= x * x\n",
        "print(y)\n",
        "\n",
        "y = torch.mm(x, x)\n",
        "print('y =', y)\n",
        "\n",
        "x = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "b=torch.tensor([[10], [10]], dtype=torch.float32)\n",
        "print(x)\n",
        "print(x.dtype)\n",
        "print(b)\n",
        "print(b.dtype)\n",
        "\n",
        "y = torch.mm(x, b)\n",
        "print(y)\n",
        "\n",
        "y = torch.transpose(x, 0, 1)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC5HVSslx2lh"
      },
      "source": [
        "## Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbFSRerVxcSL"
      },
      "source": [
        "def f1(x1, x2):\n",
        "    return 2 * x1 + x2\n",
        "\n",
        "a = torch.tensor(1.0)\n",
        "b = torch.tensor(2.5)\n",
        "print(f1(a, b))\n",
        "\n",
        "def f2(x):\n",
        "    return x ** 2 - 3\n",
        "\n",
        "x = torch.tensor(4.0)\n",
        "print('x =', x)\n",
        "print('f2(x) =', f2(x))\n",
        "\n",
        "x = torch.linspace(-10, 10, 21)\n",
        "print('x =', x)\n",
        "print('f2(x) =', f2(x))\n",
        "# Draw a figure\n",
        "plt.figure()\n",
        "plt.plot(x, f2(x))\n",
        "plt.xlim(x[0], x[-1])\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('f2(x)')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR5Hm5th2p2Z"
      },
      "source": [
        "## Derivative with scalar function\n",
        "\n",
        "$\\frac{\\partial}{\\partial x}(2x^2+3)|_{x=2} = 4x |_{x=2} = 8$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBAEmqw3yq-a"
      },
      "source": [
        "# derivative\n",
        "x = torch.tensor(2.0, requires_grad=True) # requires_grad=True indicates to store gradient\n",
        "\n",
        "print('x =', x)\n",
        "\n",
        "z = 2*(x ** 2) + 3\n",
        "\n",
        "# back-propagation (Obtain gradients using the chain rule)\n",
        "z.backward()\n",
        "print('x.grad =', x.grad)\n",
        "\n",
        "def f1(x):\n",
        "    return x**2\n",
        "\n",
        "def f2(x):\n",
        "    return 2*x+3\n",
        "\n",
        "x.grad = None # reset the previously obtained gradient\n",
        "print('x.grad =', x.grad)\n",
        "\n",
        "z=f2(f1(x))\n",
        "print('z= ', z)\n",
        "\n",
        "# back-propagation (Obtain gradients using the chain rule)\n",
        "z.backward()\n",
        "print('x.grad =', x.grad)\n",
        "\n",
        "# draw a graph of computation of y\n",
        "make_dot(z)\n",
        "\n",
        "# cf.\n",
        "# retain_grad : To retain gradients of intermediate variables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7roUNs9VxTbN"
      },
      "source": [
        "## Derivative with vector function\n",
        "$x = \\left<x_1, x_2\\right>$\n",
        "\n",
        "$y = \\left<y_1, y_2\\right> = f(x) = \\left<x_1^2+x_2, x_1+x_2^2\\right>$\n",
        "\n",
        "$z = g(y) = 2y_1 + y_2 $\n",
        "\n",
        "$\\left(\\frac{\\partial z}{\\partial x_1},  \\frac{\\partial z}{\\partial x_2} \\right)|_{x=\\left<1, 3\\right>} = \\left(5,  8\\right)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsAtumNFxTbO"
      },
      "source": [
        "def f1(x):\n",
        "    y1 = x[0] ** 2 + x[1]\n",
        "    y2 = x[0] + x[1] ** 2\n",
        "    return torch.cat([y1.reshape(1), y2.reshape(1)])\n",
        "\n",
        "def f2(x):\n",
        "    return 2 * x[0] + x[1]\n",
        "\n",
        "x = torch.tensor([1, 3], dtype=torch.float32, requires_grad=True)\n",
        "print(f1(x))\n",
        "print(f2(f1(x)))\n",
        "\n",
        "z = f2(f1(x))\n",
        "z.backward()\n",
        "print(x.grad)\n",
        "\n",
        "# draw a graph of computation of y\n",
        "make_dot(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAxsGWEq-R7k"
      },
      "source": [
        "## Higher order derivative\n",
        "\n",
        "$f(x,w) = (x+5w)^2$\n",
        "\n",
        "$f_x(x,w) = \\frac{\\partial}{\\partial x}(x+5w)^2 = 2(x+5w)$\n",
        "\n",
        "$f_w(x,w) = \\frac{\\partial}{\\partial w}(x+5w)^2 = 10(x+5w)$\n",
        "\n",
        "$f_{xx} = \\frac{\\partial f_x}{\\partial x} = 2$\n",
        "\n",
        "$f_{xw} = \\frac{\\partial f_x}{\\partial w} = 10$\n",
        "\n",
        "$f_{wx} = \\frac{\\partial f_w}{\\partial x} = 10$\n",
        "\n",
        "$f_{ww} = \\frac{\\partial f_w}{\\partial w} = 50$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA_vdJ7G_fPh"
      },
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "w = torch.tensor(3.0, requires_grad=True)\n",
        "\n",
        "def f1(x):\n",
        "  return x ** 2\n",
        "\n",
        "def f2(x, w):\n",
        "  return x + 5 * w\n",
        "\n",
        "y=f1(f2(x, w))\n",
        "\n",
        "(fx, fw) = torch.autograd.grad(outputs=y, inputs=(x, w), create_graph=True)\n",
        "print('fx =', fx)\n",
        "print('fw =', fw)\n",
        "\n",
        "fx.backward(retain_graph=True)\n",
        "print('x.grad =', x.grad)\n",
        "print('w.grad =', w.grad)\n",
        "\n",
        "x.grad = None\n",
        "w.grad = None\n",
        "fw.backward()\n",
        "print('x.grad =', x.grad)\n",
        "print('w.grad =', w.grad)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
