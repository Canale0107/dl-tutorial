{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_gpu_intro.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ3OIjdrEeoT"
      },
      "source": [
        "2021 Takahiro Shinozaki @ Tokyo Tech\n",
        "\n",
        "Quick introduction of pytorch GPU/CPU utilization\n",
        "\n",
        "References: \n",
        "*   https://pytorch.org/tutorials/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2bgINAcEvMu"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alv6Ht1MFQrJ"
      },
      "source": [
        "To use GPU, your computer have to have it.\n",
        "\n",
        "If you are using Google colab, you can request to use a computer with a GPU from the top menu : Runtime->Change Tuntime Type -> GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plGehiWVEOp3"
      },
      "source": [
        "# Check if a GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    print('CUDA（GPU）is available')\n",
        "else:\n",
        "  print('CUDA（GPU）is not available')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8BLVTqNGw4-"
      },
      "source": [
        "# Check the GPU status\n",
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT-e-CalHsDF"
      },
      "source": [
        "x = torch.tensor([[1.0,2.0],[3.0,4.0]])\n",
        "print(x)\n",
        "print(x.device)\n",
        "\n",
        "x = torch.tensor([[1.0,2.0],[3.0,4.0]], device='cpu')\n",
        "print(x)\n",
        "print(x.device)\n",
        "\n",
        "x = torch.tensor([[1.0,2.0],[3.0,4.0]], device='cuda')\n",
        "print(x)\n",
        "print(x.device)\n",
        "\n",
        "y = x.to('cpu')\n",
        "print(y)\n",
        "print(y.device)\n",
        "\n",
        "z = y.to('cuda')\n",
        "print(z)\n",
        "print(z.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_az4dQRHY9SK"
      },
      "source": [
        "Speed up by using GPU depends on the type and size of the computation.\n",
        "\n",
        "Since using GPU involves some overhead, GPU is usually more advantageous when handling larger problems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps2J9tr5CUKb"
      },
      "source": [
        "# matrix product computation using CPU/GPU\n",
        "dim=50\n",
        "print('dim= ', dim)\n",
        "\n",
        "xcpu = torch.rand(dim, dim, device='cpu')\n",
        "start_time = time.time()\n",
        "y = torch.mm(xcpu, xcpu)\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time (CPU) =', elapsed_time, 'sec')\n",
        "\n",
        "xgpu = torch.rand(dim, dim, device='cuda')\n",
        "start_time = time.time()\n",
        "y = torch.mm(xgpu, xgpu)\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time (GPU) =', elapsed_time, 'sec')\n",
        "\n",
        "dim=5000\n",
        "print('dim= ', dim)\n",
        "\n",
        "xcpu = torch.rand(dim, dim, device='cpu')\n",
        "start_time = time.time()\n",
        "y = torch.mm(xcpu, xcpu)\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time (CPU) =', elapsed_time, 'sec')\n",
        "\n",
        "xgpu = torch.rand(dim, dim, device='cuda')\n",
        "start_time = time.time()\n",
        "y = torch.mm(xgpu, xgpu)\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time (GPU) =', elapsed_time, 'sec')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN7kKY97Wruw"
      },
      "source": [
        "# matrix determinat computation using CPU/GPU\n",
        "\n",
        "dim=50\n",
        "print('dim= ', dim)\n",
        "\n",
        "xcpu = torch.rand(dim, dim, device='cpu')\n",
        "start_time = time.time()\n",
        "y = torch.linalg.det(xcpu)\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time (CPU) =', elapsed_time, 'sec')\n",
        "\n",
        "xgpu = torch.rand(dim, dim, device='cuda')\n",
        "start_time = time.time()\n",
        "y = torch.linalg.det(xgpu)\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time (GPU) =', elapsed_time, 'sec')\n",
        "\n",
        "dim=5000\n",
        "print('dim= ', dim)\n",
        "\n",
        "xcpu = torch.rand(dim, dim, device='cpu')\n",
        "start_time = time.time()\n",
        "y = torch.linalg.det(xcpu)\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time (CPU) =', elapsed_time, 'sec')\n",
        "\n",
        "xgpu = torch.rand(dim, dim, device='cuda')\n",
        "start_time = time.time()\n",
        "y = torch.linalg.det(xgpu)\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time (GPU) =', elapsed_time, 'sec')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYzG5Pm1Jl4s"
      },
      "source": [
        "# eigenvalues computation using CPU/GPU\n",
        "\n",
        "x = torch.tensor([[1.0,0.0],[0.0,3.0]])\n",
        "e,v = torch.linalg.eig(x)\n",
        "print(e)\n",
        "print(v)\n",
        "\n",
        "dim=50\n",
        "print('dim= ', dim)\n",
        "\n",
        "xcpu = torch.rand(dim, dim, device='cpu')\n",
        "start_time = time.time()\n",
        "e, v = torch.linalg.eig(xcpu)\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time (CPU) =', elapsed_time, 'sec')\n",
        "\n",
        "xgpu = torch.rand(dim, dim, device='cuda')\n",
        "start_time = time.time()\n",
        "e, v = torch.linalg.eig(xgpu)\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time (GPU) =', elapsed_time, 'sec')\n",
        "\n",
        "\n",
        "dim=5000\n",
        "print('dim= ', dim)\n",
        "\n",
        "xcpu = torch.rand(dim, dim, device='cpu')\n",
        "start_time = time.time()\n",
        "e, v = torch.linalg.eig(xcpu)\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time (CPU) =', elapsed_time, 'sec')\n",
        "\n",
        "xgpu = torch.rand(dim, dim, device='cuda')\n",
        "start_time = time.time()\n",
        "e, v = torch.linalg.eig(xgpu)\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time (GPU) =', elapsed_time, 'sec')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}