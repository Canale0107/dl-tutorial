{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_optim_intro.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPuwlhnZ6gUw"
      },
      "source": [
        "2021 Takahiro Shinozaki @ Tokyo Tech\n",
        "\n",
        "Quick introduction of neural network training using optimizer\n",
        "\n",
        "References:\n",
        "\n",
        "    https://pytorch.org/docs/stable/optim.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX6T6-dzpbP7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyvzy3PmTvlX"
      },
      "source": [
        "# Check if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "  print('CUDA（GPU）is available')\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  print('CUDA（GPU）is not available')\n",
        "  device = 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v1WEZqITycM"
      },
      "source": [
        "# Generate simulated data\n",
        "NumSamples = 10000\n",
        "torch.manual_seed(0)\n",
        "# two dimensional data\n",
        "x = (torch.randn(NumSamples,2)*2.0).to(device)\n",
        "# label is three categories (0,1,2)\n",
        "y = ((torch.sin(x[:,0])*0.9+torch.cos(x[:,1])*0.9).long()+1).to(device)\n",
        "plt.scatter(x[:,0].to('cpu'),x[:,1].to('cpu'),c=y.to('cpu'))\n",
        "print(x.dtype)\n",
        "print(y.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znq1IML8dA1G"
      },
      "source": [
        "# Prepare train, dev, test sets\n",
        "x_train = x[0:int(NumSamples * 0.8)]\n",
        "x_dev = x[int(NumSamples * 0.8):int(NumSamples * 0.9)]\n",
        "x_test = x[int(NumSamples * 0.9):NumSamples]\n",
        "\n",
        "y_train = y[0:int(NumSamples * 0.8)]\n",
        "y_dev = y[int(NumSamples * 0.8):int(NumSamples * 0.9)]\n",
        "y_test = y[int(NumSamples * 0.9):NumSamples]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l22BYOL-O6b"
      },
      "source": [
        "# An alternative test set using meshgrid. \n",
        "a = b = torch.linspace(-5, 5, 101)\n",
        "x_mesh = torch.flatten(torch.stack(torch.meshgrid(a,b),2),0,1).to(device)\n",
        "y_mesh = ((torch.sin(x_mesh[:,0])*0.9+torch.cos(x_mesh[:,1])*0.9).long()+1).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZheSXFohkNi"
      },
      "source": [
        "# Prepare data loader for mini-batch training\n",
        "BatchSize = 15 \n",
        "\n",
        "dataset_train = TensorDataset(x_train, y_train)\n",
        "dataset_dev = TensorDataset(x_dev, y_dev)\n",
        "dataset_test = TensorDataset(x_test, y_test)\n",
        "\n",
        "loader_train = DataLoader(dataset_train, batch_size=BatchSize, shuffle=True, drop_last=True)\n",
        "loader_dev = DataLoader(dataset_dev, batch_size=BatchSize)\n",
        "loader_test = DataLoader(dataset_test, batch_size=BatchSize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRH9JIDPkUle"
      },
      "source": [
        "# Define neural network\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.layer1 = nn.Linear(2, 100)\n",
        "        self.layer2 = nn.Linear(100,20)\n",
        "        self.layer_out = nn.Linear(20,3)\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = nn.Sigmoid()(self.layer1(z))\n",
        "        z = nn.Sigmoid()(self.layer2(z))\n",
        "        z = self.layer_out(z)  # Pre-sigmoid output for nn.CrossEntropyLoss\n",
        "        return z\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUIxZT9878Lo"
      },
      "source": [
        "# Make an instance of the neural network\n",
        "model = NeuralNetwork().to(device)\n",
        "params = model.state_dict()\n",
        "print('params =', params)\n",
        "print(params['layer1.weight'].device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HhEVypk1jJN"
      },
      "source": [
        "# Prepare an optimizer\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.02, weight_decay=0.001)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.02)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUFJGGw62DRr"
      },
      "source": [
        "# Define a step of batch processing\n",
        "def train_step(x, y):\n",
        "    model.train() # set train mode\n",
        "\n",
        "    out = model(x) # forward propagation\n",
        "    optimizer.zero_grad() # clear gradients\n",
        "    loss = criterion(out, y)\n",
        "    loss.backward() # calculate gradient\n",
        "\n",
        "    optimizer.step() # update network parameters\n",
        "\n",
        "    with torch.no_grad(): # no gradient computation\n",
        "        num_crr = (y == torch.argmax(out,1)).sum()\n",
        "\n",
        "    return (loss.item(), num_crr.item()) # touple of loss and correct count\n",
        "\n",
        "def test_step(x, y):\n",
        "    model.eval() # set evaluation mode\n",
        "\n",
        "    out = model(x)\n",
        "    loss = criterion(out, y)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        num_crr = (y == torch.argmax(out,1)).sum()\n",
        "\n",
        "    return (loss.item(), num_crr.item())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDtxYGiU83tW"
      },
      "source": [
        "# Train the model\n",
        "NumEpocs = 50\n",
        "log_train = []\n",
        "log_dev = []\n",
        "for epoch in range(NumEpocs):\n",
        "    train_loss_total = 0.0\n",
        "    train_num_crr_total = 0.0\n",
        "    dev_loss_total = 0.0\n",
        "    dev_num_crr_total = 0.0\n",
        "    num_train_sample = 0\n",
        "    num_dev_sample = 0\n",
        "\n",
        "    # mini-batch processings\n",
        "    for x, y in loader_train:\n",
        "        loss, num_crr = train_step(x, y)\n",
        "        train_loss_total += loss\n",
        "        train_num_crr_total += num_crr\n",
        "        num_train_sample += len(y)\n",
        "            \n",
        "    for x, y in loader_dev:\n",
        "        loss, num_crr = test_step(x, y)\n",
        "        dev_loss_total += loss\n",
        "        dev_num_crr_total += num_crr\n",
        "        num_dev_sample += len(y)\n",
        "            \n",
        "    train_loss_avg = train_loss_total / num_train_sample\n",
        "    train_crr_avg = train_num_crr_total / num_train_sample\n",
        "    dev_loss_avg = train_loss_total / num_train_sample\n",
        "    dev_crr_avg = train_num_crr_total / num_train_sample\n",
        "\n",
        "    log_train.append(train_loss_avg)\n",
        "    log_dev.append(dev_loss_avg)\n",
        "\n",
        "    print(f'[Epoch {epoch+1:3d}]' \\\n",
        "          f' tr_loss: {train_loss_avg:.5f}, tr_crr: {train_crr_avg:.5f}' \\\n",
        "          f' dev_loss: {dev_loss_avg:.5f}, dev_crr: {dev_crr_avg:.5f}')\n",
        "\n",
        "print('Done training')\n",
        "# print(model.state_dict())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0DQj4u7vKUv"
      },
      "source": [
        "# Evaluation using the test set\n",
        "model.eval() # set evaluation mode\n",
        "out = model(x_test)\n",
        "c = torch.argmax(out, 1)\n",
        "test_crr = (y_test == c).sum().to('cpu')/torch.tensor(y_test.size())\n",
        "print('test_crr =', test_crr.item())\n",
        "plt.scatter(x_test[:,0].to('cpu'),x_test[:,1].to('cpu'),c=c.to('cpu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiYtQkit9gKg"
      },
      "source": [
        "# Distribution of errors\n",
        "plt.scatter(x_test[:,0].to('cpu'),x_test[:,1].to('cpu'),c=(c-y_test).to('cpu'))\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5umNpWRQICPK"
      },
      "source": [
        "# Systematic evaluation of the input domain using the mesh data\n",
        "model.eval() # set evaluation mode\n",
        "out = model(x_mesh)\n",
        "c = torch.argmax(out, 1)\n",
        "mesh_crr = (y_mesh == c).sum().to('cpu')/torch.tensor(y_mesh.size())\n",
        "print('mesh_crr =', mesh_crr.item())\n",
        "plt.scatter(x_mesh[:,0].to('cpu'),x_mesh[:,1].to('cpu'),c=c.to('cpu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeNRYzt0ICav"
      },
      "source": [
        "# Distribution of errors\n",
        "plt.scatter(x_mesh[:,0].to('cpu'),x_mesh[:,1].to('cpu'),c=(c-y_mesh).to('cpu'))\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}